---

marp: true
theme: defalut
paginate: true
footer: 

---
<style>
img[alt~="center"] {
  display: block;
  margin: 0 auto;
}
</style>
# Betriebssysteme
## I/O - Teil 1: I/O Devices

Prof. Dr.-Ing. Andreas Heil

![h:32 CC 4.0](../img/cc.svg)![h:32 CC 4.0](../img/by.svg) Licensed under a Creative Commons Attribution 4.0 International license. Icons by The Noun Project.

<!--version-->
v1.0.0
<!--/version-->

---

# Lernziele und Kompetenzen

**Verstehen** wie I/O Devices grunds√§tzlich aufgebaut sind und wie sich diese in das Betriebssystem integrieren

--- 


# Motivation

* Gedankenspiel:
  * Was w√§re ein Programm ohne Eingabe? Es lieferte immer die gleiche Antwort\.
  * Was w√§re ein Programm ohne Ausgabe?  ü§î
* Ein\-/Ausgabe stellt somit einen zentralen Aspekt von Rechnern dar.
  * Wie l√§sst sich Ein\-/Ausgabe in ein System integrieren?
  * Was sind die grundlegenden Mechanismen?
  * Wie k√∂nnen diese effizient umgesetzt werden?

---

# Ein-/Ausgabe Ger√§te

Ger√§te zur Eingabe/Ausgaben \(engl\.input/output devices, kurz I/O devices\)  h√§ngen stark von der Systemarchitektur ab.

* Wie sollte I/O grunds√§tzlich in das System integriert werden?
* Was sind die grundlegenden Mechanismen?
* Wie k√∂nnen I/O-Operationen effizient gehandhabt werden?

![bg right w:640](../img/os.22.io.de.png)

---

# 1,2,3 BUS

* Wir unterscheiden zwischen
  * Speicher\-Bus zur schnellen Anbindung des Hauptspeichers
  * Einem allgemeinen I/O\-Bus zur systeminternen Kommunikation \(bei modernen Ger√§ten ist dies PCI\)
  * Peripherie\-Bus \(SCSI\, SATA oder USB\)
* Warum aber mehrere Bus\-Systeme?
  * Physik und Kosten sind hier die ma√ügeblichen Gr√∂√üen
  * Je schneller der Bus\, desto k√ºrzer
  * Je schneller der Bus\, desto teurer

---

# I/O Chips

* Moderne Architekturen nutzen daher spezielle I/O Chips zum schnellen Routen von Daten
* Beispiel f√ºr einen solchen Chip ist Intel DMI \(Direct Media Interface\)
* Anbindung von Festplatten via eSATA \(external SATA\) als Weiterentwicklung von SATA \(Serial ATA\) als Weiterentwicklung von ATA bzw. IBM AT Attachment (2. IBM PC Generation mit 6 MHz Intel 80286 CPUs))
* USB ‚Äì Universal Serial Bus f√ºr sog\. Low Performance Devices

---

# Einsatz von I/O Chips

![center h:600](../img/os.22.bus.de.png/)

---

# Canonical Device

* Grundlegendes \(allgemeing√ºltiges\) Konzept eines Ger√§tes
  * Besteht aus zwei wichtigen Komponenten:
  * Hardware Interface, √ºber den das das Ger√§t angesteuert werden kann
  * Interne Strukturen
    * Implementierungsabh√§ngig
    * Ein paar Chips\, komplexere Ger√§te sogar mit einer CPU
    * Allgemeiner Speicher und weitere Chips

![center h:200 ](../img/os.22.canonical_device.de.png)

---

# Canonical Protocol

* Allgemeing√ºltiges Protokoll zur Ansteuerung von I/O-Ger√§ten
* Im Beispiel zuvor: 3 Register
  * Status Register: Erm√∂glicht es\, den Status des Ger√§ts auszulesen
  * Command Register: Erm√∂glicht es\, dem Ger√§t mitzuteilen\, welche Aktion als n√§chstes ausgef√ºhrt werden soll
  * Data Register: Erm√∂glicht es Daten ins Ger√§t zu √ºbermitteln
  * Durch Schreiben/Lesen dieser Register wird die Interkation mit dem Ger√§t erm√∂glicht

---

# Das Protokoll in 4 Schritten

1. Warten bis das Ger√§t bereit ist
2. Daten in Register schreiben
3. Kommando in Register schreiben
4. Warten bis Ger√§t fertig ist

```
while \(STATUS == BUSY\)
; // wait until device is not busy
write data to DATA register
write command to COMMAND register
(starts the device and executes the command\)
while \(STATUS == BUSY\) ;
// wait until device is done with your request
```

---

# Polling

  * Das Status Register fortw√§hrend auszulesen wird auch __Polling__ genannt
  * Im Grund wird andauernd gefragt: ‚ÄûEy Digga\, was geht?\!‚Äú
  * Abh√§ngig von der Gr√∂√üe des Daten Registers sind hier mehrere Durchl√§ufe erforderlich\, bis alle Daten geschrieben sind

---

# PIO

  * Sobald die CPU \(hier meinen wir die CPU vom Rechner\, nicht vom I/O Ger√§t\) f√ºr das "Hin\- und Herschippern" der Daten genutzt wird, sprechen wir von __programmed__  __I/O \(Abk\. PIO\)__
  * Das Protokoll funktioniert im Grunde ABER
  * Polling ist kostenintensiv
    * Verschwendet CPU Cycles
    * Verlangsamt oder blockiert die Ausf√ºhrung anderer Prozesse
    * F√ºhrt die Idee des Overlapping beim Scheduling ad absurdum

---

# Interrupts

* Idee: Den CPU Overhead mittels Interrupts reduzieren
* Grunds√§tzliche Funktionsweise
  * Betriebssystem stellt eine Anfrage an ein Ger√§t
  * Der aufrufende Prozess wird schlafen geschickt
  * Betriebssystem f√ºhrt einen Kontext\-Switch zu einem anderen Prozess aus
  * Sobald das Ger√§t fertig ist\, wird ein Hardware Interrupt ausgel√∂st
  * Der Interrupt veranlasst das Betriebssystem eine vordefinierten __Interrupt Service Routine__ \(ISR\) bzw. __Interrupt Handler__ auszuf√ºhren\.

---

# Polling vs Interrupts

In dem erste Beispiel pollt die CPU\, bis das Ger√§t fertig ist.

Mit einem Interrupt k√∂nnte die CPU in der Zwischenzeit etwas anders \(sinnvolles\) machen.

![center h:320](../img/os.22.polling.de.png)

---

# Performance

* Interrupts sind nicht immer die beste L√∂sung
  * Wenn das Ger√§t so schnell ist\, dass beim ersten Poll die Antwort k√§me\, machen Interrupts das System langsamer
  * Der damit zusammenh√§ngenden context Switch ist im Verh√§ltnis zum ‚Äûkurz Warten‚Äú teurer

---

# Livelocks

Zu viele Interrupts k√∂nnen das System auch √ºberlasten

In diesem Fall sprechen wir von einem __Livelock__

![center](../img/os.22.livelock.de.png)


---

# L√∂sung: Hybrid Ansatz

Die L√∂sung zum\, vorherigen Problem: Zwei Phasen

* F√ºr einen kurzen Zeitraum pollen
* Wenn das Ger√§t nicht geantwortet hat einen Interrupt nutzen

Ein konkretes Beispiel:Ein Web\-Server erh√§lt pl√∂tzlich \(extrem\) viele Anfragen\. Wenn nun bei eintreffenden Paketen nur noch Interrupts ausgel√∂st werden\, l√§uft im Prinzip kein Prozess mehr im User\-Space\.Daher w√§re es besser den Web\-Server selbst entscheiden zu lassen wann er neue Pakete entgegen nimmt\.

---

# Alternativer L√∂sungsansatz: Coalesing

* Wenn ein Ger√§t fertig ist\, wird der Interrupt nicht sofort ausgel√∂st\!
  * Anstelle dessen wartet das Ger√§t einen Moment ob bzw. bis weiter Anfragen abgearbeitet sind
  * Nun werden alle bearbeitet Requests geb√ºndelt zur√ºck geliefert, in dem der Interrupt nur einmal ausgel√∂st wird
* Nachteil
  * Zu langes Warten kann zu einer erh√∂hten Latenz des Ger√§tes f√ºhren

---

# Datenschubsen

Nicht nur das Polling auch bei anderen Aufgaben wird die CPU f√ºr eigentlich triviale Aufgaben in Anspruch genommen: z.B. das Kopieren von Daten in die Daten Register

Frage: Wie kann der CPU Arbeit abgenommen werden\, damit die CPU effizienter genutzt werden kann? Ganz einfach: Kopieren der Daten

![center h:200](../img/os.22.copy.de.png)

---

# DMA: Direct Memory Access

* Eine separate DMA Engine orchestriert den Datenfluss zwischen Ger√§t und Hauptspeicher
  * Funktionsweise: Das Betriebssystem programmiert die DMA Engine mit
    * Speicherort an dem die Daten liegen
    * Wie viele Daten kopiert werden sollen
    * An welches Ger√§t die Daten geschickt werden sollen und ist jetzt quasi fertig!

![center h:200](../img/os.22.dma.de.png)

---

# Kommunikation mit dem Ger√§t

Nun stellt sich noch die Frage\, wie die ganzen Ger√§te mit ihren spezifischen Hardware Interfaces in das Betriebssystem passen\.

Ziel: Betriebssystem so gut wie es geht Ger√§te\-neutral halten\, also die Details der Ger√§teinteraktion vom Betriebssystem ‚Äûverstecken‚Äú\.

L√∂sung: Wie so oft in der Informatik hilft uns hier die __Abstraktion__ \!

![center h:200](../img/os.22.abstraction.de.png)

---

# Ger√§tetreiber

Die ger√§tespezifische Funktionalit√§t wird als Ger√§tetreiber ausgeliefert\.

Nachteil: Durch die generische Schnittstelle k√∂nnen nicht immer alle \(tollen\) Funktionen eines Ger√§ts genutzt werden\.

Beispiel: SCSI Error\-Funktionalit√§t ist unter Linux √ºber die einfachere ATA/DIE Schnittstelle nicht nutzbar\.

Bedeutung von Ger√§tetreibern:Bis zu 70% des Codes eines Betriebssystems \(Linux und Windows ann√§hernd gleich viel\) steckt heute inzwischen in Ger√§tetreibern\.

__Problem__ : Dieser Code wird nicht von Kernel\-Entwicklern gebaut\.

---

# Referenzen