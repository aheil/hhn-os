---

marp: true
theme: defalut
paginate: true
footer: 

---
<style>
img[alt~="center"] {
  display: block;
  margin: 0 auto;
}
</style>
# Scheduler 
## Teil 1: CPU-Scheduling 
Prof. Dr.-Ing. Andreas Heil

![h:32 CC 4.0](../img/cc.svg)![h:32 CC 4.0](../img/by.svg) Licensed under a Creative Commons Attribution 4.0 International license. Icons by The Noun Project.

v1.1.1

---

# Wiederholung

* Direct Execution
    * Weshalb ist es keine gute Idee, Prozesse direkt auszufÃ¼hren? 
* SysCalls
    * Woher weiÃŸ die Hardware, welcher Betriebssystem-Code ausgefÃ¼hrt werden soll?
    * Wie lÃ¤sst sich dies als Angriffsvektor nutzen?
* Stack
    * Wie ist die grundlegende Funktionsweise eines Stacks?

---

# Lernziele und Kompetenzen

* Grundlagen der Scheduling-Mechanismen **kennen lernen** 
* **Verstehen** wie Prozesse von Betriebssystemen Â»gescheduledÂ« werden kÃ¶nnen


---

# Eine kurze Wiederholung

Bisher kennen gelernt:

* Â»Low-Level-MechanismenÂ« von laufenden Prozessen (z.B. Context Switch)
* Falls nicht klar, Einheit 1 wiederholen + Kapitel 4-6 aus *Operating Systems: Three Easy Pieces*[^1] wiederholen

Was fehlt noch? 
* Wann darf welcher Prozess laufen (engl. scheduling)

---

# Scheduling Policy

* Die Â»Scheduling PolicyÂ« (also das Regelwerk) hÃ¤ngt vorrangig vom Â»WorkloadÂ« der Prozesse ab
* Zur Vereinfachung werden zunÃ¤chst folgende (absolut unrealistische) Annahmen getroffen:
    * Jeder Job lÃ¤uft gleich lang
    * Alle Jobs treffen zur gleichen Zeit ein
    * Einmal gestartet, lÃ¤uft ein Job bis er beendet ist
    * Alle Jobs verwenden ausschlieÃŸlich die CPU
    * Laufzeit (engl. runtime) eines jeden Jobs ist bekannt

---

# Scheduler Metriken: Turnaround-Zeit


* Hinweis: Metriken werden im 3. Semester in SEKS vertieft 
* FÃ¼r heute genÃ¼gt: Metrik = einfach um etwas zu messen
* FÃ¼r uns: zunÃ¤chst nur eine Metrik

$$
T_{turnaround}=T_{completion}-T_{arrival}
$$

Aufgrund unserer vorherigen Annahmen gelten
* Alle Jobs kommen zum  gleichen Zeitpunkt an: $T_{arrival} = 0$
* Somit gilt: $T_{turnaround}=T_{completion}$

---

# First In, First Out (1)

First in, First out (abk. FIFO) oder manchmal auch First Come, First Serve (abk. FCFS)
* Einfach und daher auch einfach zu implementieren
* Beispiel
    * Jobs A, B und C kommen kurz nacheinander an
    * Jeder Job hat eine Laufzeit von 10 Sekunden
    * Was ist die durchschnittliche Turnaround-Zeit?
    * $\frac{10+20+30}{3}=20$

![w:320 center](../img/os.03.fifo.png)

---

# First In, First Out (2)

* Heben wir jetzt die erste Annahme auf
    * Zur Erinnerung: Jeder Job lÃ¤uft gleich lang
    * Ab sofort: Jeder Job lÃ¤uft eben nicht mehr gleich lang
    * Gibt es einen Workload, der FIFO Â»alt aussehen lÃ¤sstÂ«?
    * $\frac{100+110+120}{3}=110$

![w:320 center](../img/os.03.fifo_bad.png)

---

<!-- footer: Photo by Paul Townsend, licensed under Attribution-ShareAlike 2.0 Generic (CC BY-SA 2.0)-->

# Convoy Effect (dt. Konvoieffekt)

* Kennt jeder
* Mehrere Kunden mit wenigen Waren warten hinter einem einzigen Kunden mit vielen Waren 
* Nur eine Supermarktkasse offen... ğŸ˜¤

![bg right h:550](../img/os.03.convoy.jpg)

---

<!-- footer: "" -->

# Shortest Job First

* Shortest Job first (Abk. SJF)
* Beschreibt die Policy recht treffend 
    * FÃ¼hrt den kÃ¼rzesten Job aus, dann den zweit kÃ¼rzesten etc.
* Beispiel von zuvor
    * SJF reduziert Turnaround-Zeit von 110 auf 50 
* $\frac{10+20+120}{3}=50$

![w:320 center](../img/os.03.sjf.png)

---

# Problem bei SJF

* LÃ¶sen wir ab jetzt die Restriktion, dass alle Jobs zum selben Zeitpunkt eintreffen
* Beispiel: A trifft bei $ğ‘¡=0$, B und C bei $ğ‘¡ = 10$ ein
* Turnaround-Zeit hat sich hierdurch verdoppelt
* $\frac{100+(110-10)+(120-10)}{3}=103,33$

![w:320 center](../img/os.03.sjf_bad.png)

---

# Exkurs: Non-Preemptive vs. Preemptive 

* Non-Preemptive 
    * Stammt aus den Zeiten von sog. Batch-Systemen
    * Jeder Job wurde zu Ende gerechnet, bevor Ã¼berhaupt in ErwÃ¤gung gezogen wurde einen anderen Job zu starten 

* Preemptive
    * Alle modernen Betriebssysteme sind Â»preemptiveÂ«
    * Jederzeit gewillt einen Job zu stoppen und einen anderen dafÃ¼r zu starten
    * Nutzen den zuvor behandelten Context Switch

---

# Shortest Time-to-Completion First (STCF)

* SJF ist non-preemptive â–¶ versuchen wir es preemptive
* LÃ¶sen wir nun die Restriktion, dass alle Jobs bis zum Ende durchlaufen 
* Jedes Mal wenn ein Job eintrifft, wird derjenige der die geringste Restlaufzeit
* **Achtung!** Das geht nur wegen unserer letzten noch bestehenden Annahme: Die (Rest-)Laufzeit ist bekannt! 

* $\frac{(120-0)+(20-10)+(30-10)}{3}=50$

![w:320 center](../img/os.03.stcf.png)

---

<!-- footer: Bild von Gerd Altmann auf Pixabay -->

# Problem mit STCF

* Benutzer wartet bis Job A (z.B. Aktualisierung in Excel o.Ã¤.) fertig ist
* Nun kommt die Hausaufgabe vom letzten Mal ins Spiel: Sie erinnern sich an den Unterschied zwischen Foreground- und Background-Jobs?  
* Was ist denn, wenn andauernd neue kÃ¼rzere Jobs eintreffen, die keine Benutzereingabe erfordernâ€¦ ğŸ¥±

![bg right w:550](../img/os.03.wait.jpg)

---

<!-- footer: "" -->

# Scheduler Metriken: Antwortzeit

* Zweite Metrik fÃ¼r heute: Antwortzeit (eng. response time)
* Dauer vom Zeitpunkt an dem Job eintrifft bis er das erste Mal Â»gescheduledÂ« wird
* $\frac{0 + 5 + 10}{3}=5$

$$
T_{response}=T_{firstrun}-T_{arrival}
$$

![w:320 center](../img/os.03.sjf_responsetime.png)

---

# Round Robin (RR)

* Grundprinzip: Jeder Job wird nur fÃ¼r eine bestimmte Zeitspanne (engl. time slice) ausgefÃ¼hrt 
* Zeitscheibe ist ein Vielfaches vom Timer Interrupt (d.h. bei einem Timer Interrupt von 10ms ein Vielfaches von 10)
* Durchschnittliche Antwortzeit im Vergleich zu SJF (vorherige Folie) ist 1
* $\frac{0 + 1 + 2}{3}=1$

![w:320 center](../img/os.03.rr_responsetime.png)

---

# Round Robin (Forts.)

* Der Context Switch kostet Ressourcen
* D.h. wie lange mÃ¼ssten die Time Slices sein, dass sich ein Context Switch Ã¼berhaupt lohnt?
* FÃ¼r Antwortzeit hervorragend geeignet, fÃ¼r Turnaround-Zeit Ã¼berhaupt nicht
* Round Robin zieht AusfÃ¼hrungsdauer in die LÃ¤nge, in manchen FÃ¤llen ist die AusfÃ¼hrung sogar schlechter als FIFO  
* Allgemein lÃ¤sst sich festhalten: Jede Policy die fair ist, d.h. die CPU auf Prozesse aufteilt, fÃ¼hrt zu einem schlechten Ergebnis in Bezug auf Turnaround-Zeit 

---

# Kurzer Zwischenstand

* Wir haben zwei Typen von Schedulern kennen gelernt 
    * SJF/STCF optimiert Turnaround-Zeiten, ist jedoch ungÃ¼nstig fÃ¼r Antwortzeiten 
    * RR optimiert die Antwortzeit, ist aber ungÃ¼nstig fÃ¼r die Turnaround-Zeit

* Es gibt noch zwei Annahmen/Restriktionen, die Â»aufgelÃ¶stÂ« werden mÃ¼ssen
    4. Alle Jobs verwenden ausschlieÃŸlich die CPU
    5. Laufzeit eines jedes Jobs ist bekannt

---

# Input/Output

* LÃ¶sen wir die nÃ¤chste Restriktion: Ab sofort kÃ¶nnen Jobs auch I/O-Operationen aufrufen
* Scheduler muss nun entscheiden wann eine I/O-Operation durchgefÃ¼hrt wird, da in der Zeit der laufende Prozess die CPU nicht nutzen kann und sich somit im Status Â»blockedÂ« befindet
* Scheduler kann demnach in dieser Zeit einen anderen Job laufen lassen
* Ist die I/O-Operation fertig (wird Ã¼ber Interrupt angezeigt), wird der zuvor geblockte Job wieder auf Â»readyÂ« gesetzt
* Ab jetzt kann er Job potentiell wieder laufen

---

# Overlapping

* Schlechte Ressourcen-Nutzung
    ![center](../img/os.03.schechte_ressourcennutzung.png)

* Bessere Ressourcen-Nutzung dank Overlapping
![center](../img/os.03.overlapping.png)

---

# Kein Wissen Ã¼ber Prozessdauer

* Als letzte Restriktion lÃ¶sen wir nun die Kenntnisse Ã¼ber die Prozesslaufzeit auf 
* D.h. der Scheduler weiÃŸ nichts Ã¼ber die Restlaufzeit eines Prozesses
* Wie kann dann sinnvoll gescheduled werden? 

LÃ¶sungsidee: sog. Â»Multi-Level Feedback QueueÂ«-AnsÃ¤tze verwenden die nahe Vergangenheit, um die Zukunft vorauszusagen! ğŸ¤©


---

# Referenzen 

[^1]: http://pages.cs.wisc.edu/~remzi/OSTEP/